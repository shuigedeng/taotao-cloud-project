<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<contextName>${APP_NAME}</contextName>
	<springProperty name="APP_NAME" scope="context" source="spring.application.name"/>
	<springProperty name="LOG_FILE" scope="context" source="logging.file"
					defaultValue="../logs/application/${APP_NAME}"/>
	<springProperty name="LOG_MAX_FILE_SIZE" scope="context" source="logback.filesize" defaultValue="100MB"/>
	<springProperty name="LOG_FILE_MAX_DAY" scope="context" source="logback.filemaxday" defaultValue="15"/>
	<springProperty name="SERVER_IP" scope="context" source="spring.cloud.client.ip-address" defaultValue="0.0.0.0"/>
	<springProperty name="SERVER_PORT" scope="context" source="server.port" defaultValue="0000"/>
	<springProperty name="BOOTSTRAP_SERVERS" scope="context" source="spring.kafka.bootstrap-servers"
					defaultValue="localhost:9092"/>

	<!-- 彩色日志 -->
	<!-- 彩色日志依赖的渲染类 -->
	<conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
	<conversionRule conversionWord="wex"
					converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
	<conversionRule conversionWord="wEx"
					converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>

	<!-- 彩色日志格式 -->
	<property name="CURRENT_DATE" value="%d{yyyy-MM-dd}"/>
	<property name="CONSOLE_LOG_PATTERN"
			  value="[${APP_NAME}:${SERVER_IP}:${SERVER_PORT}] %clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(%level){blue} %clr(${PID}){magenta} %clr([%X{t-traceId}]){yellow} %clr([%thread]){orange} %clr(%logger){cyan} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>
	<property name="CONSOLE_LOG_PATTERN_NO_COLOR"
			  value="[${APP_NAME}:${SERVER_IP}:${SERVER_PORT}] %d{yyyy-MM-dd HH:mm:ss.SSS} %level ${PID} [%X{t-traceId}] [%thread] %logger %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}"/>

	<!-- 控制台日志 -->
	<appender name="CONSOLE_APPENDER" class="ch.qos.logback.core.ConsoleAppender">
		<withJansi>true</withJansi>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN}</pattern>
			<charset>UTF-8</charset>
		</encoder>
	</appender>

	<!-- 按照每天生成常规日志文件 -->
	<appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_FILE}/${APP_NAME}-INFO.log</file>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN_NO_COLOR}</pattern>
			<charset>UTF-8</charset>
		</encoder>
		<!-- 基于时间的分包策略 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${LOG_FILE}/${APP_NAME}-INFO.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
			<!--保留时间,单位:天-->
			<maxHistory>${LOG_FILE_MAX_DAY}</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>${LOG_MAX_FILE_SIZE}</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_FILE}/${APP_NAME}-DEBUG.log</file>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN_NO_COLOR}</pattern>
			<charset>UTF-8</charset>
		</encoder>
		<!-- 基于时间的分包策略 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${LOG_FILE}/${APP_NAME}-DEBUG.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
			<!--保留时间,单位:天-->
			<maxHistory>${LOG_FILE_MAX_DAY}</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>${LOG_MAX_FILE_SIZE}</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>DEBUG</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_FILE}/${APP_NAME}-WARN.log</file>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN_NO_COLOR}</pattern>
			<charset>UTF-8</charset>
		</encoder>
		<!-- 基于时间的分包策略 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${LOG_FILE}/${APP_NAME}-WARN.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
			<!--保留时间,单位:天-->
			<maxHistory>${LOG_FILE_MAX_DAY}</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>${LOG_MAX_FILE_SIZE}</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>WARN</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_FILE}/${APP_NAME}-ERROR.log</file>
		<encoder>
			<pattern>${CONSOLE_LOG_PATTERN_NO_COLOR}</pattern>
			<charset>UTF-8</charset>
		</encoder>
		<!-- 基于时间的分包策略 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${LOG_FILE}/${APP_NAME}-ERROR.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
			<!--保留时间,单位:天-->
			<maxHistory>${LOG_FILE_MAX_DAY}</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>${LOG_MAX_FILE_SIZE}</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>ERROR</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<appender name="KAFKA_APPENDER" class="com.taotao.cloud.log.appender.TaotaoKafkaAppender">
		<encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
			<providers class="net.logstash.logback.composite.loggingevent.LoggingEventJsonProviders">
				<!--<timestamp>-->
				<!--    <timeZone>GMT+8</timeZone>-->
				<!--</timestamp>-->
				<pattern>
					<pattern>
						{
						"application_name": "${APP_NAME:-}",
						"trace_id": "%X{t-traceId:-}",
						"server_ip": "${SERVER_IP:-}",
						"server_port": "${SERVER_PORT:-}",
						"timestamp": "%d{yyyy-MM-dd HH:mm:ss.SSS}",
						"logday": "%d{yyyy-MM-dd}",
						"thread": "%thread",
						"pid": "${PID:-}",
						"parent_span_id" : "%X{X-B3-ParentSpanId:-}",
						"span_id": "%X{X-B3-SpanId:-}",
						"exportable": "%X{X-Span-Export:-}",
						"logger": "%logger{36}",
						"level": "%p",
						"message": "%msg",
						"host": "${SERVER_IP:-}",
						"stack_trace": "%ex",
						"source": "taotao_cloud_sys_log"
						}
					</pattern>
				</pattern>
			</providers>
		</encoder>
		<topic>taotao-cloud-sys-log</topic>
		<keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
		<deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
		<producerConfig>bootstrap.servers=${BOOTSTRAP_SERVERS}</producerConfig>
		<producerConfig>key.serializer=org.apache.kafka.common.serialization.StringSerializer</producerConfig>
		<producerConfig>value.serializer=org.apache.kafka.common.serialization.StringSerializer</producerConfig>
		<producerConfig>acks=0</producerConfig>
		<producerConfig>retries=0</producerConfig>
		<producerConfig>batch.size=10</producerConfig>
		<producerConfig>buffer-memory=33554432</producerConfig>
		<producerConfig>linger.ms=1000</producerConfig>
		<producerConfig>max.block.ms=0</producerConfig>
	</appender>

	<appender name="KAFKA_ASYNC_APPENDER" class="ch.qos.logback.classic.AsyncAppender">
		<appender-ref ref="KAFKA_APPENDER"/>
	</appender>

	<logger name="org.apache.kafka" level="off"/>

	<!--为某个包单独配置logger
    比如定时任务，写代码的包名为：net.add1s.slf4j-logback
    步骤如下：
    1、定义一个appender，取名为task（随意，只要下面logger引用就行了）
    appender的配置按照需要即可

    2、定义一个logger:
    <logger name="net.add1s.slf4j-logback" level="DEBUG" additivity="false">
      <appender-ref ref="task" />
    </logger>
    注意：additivity必须设置为false，这样只会交给task这个appender，否则其他appender也会打印net.add1s.slf4j-logback里的log信息。

    3、这样，在net.add1s.slf4j-logback的logger就会是上面定义的logger了。
    private static Logger logger = LoggerFactory.getLogger(Class1.class);
    -->

	<springProfile name="dev">
		<logger name="com.sdcm.pmp" level="debug"/>
	</springProfile>

	<root level="INFO">
		<appender-ref ref="CONSOLE_APPENDER"/>
		<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
		<appender-ref ref="INFO_FILE"/>
		<appender-ref ref="DEBUG_FILE"/>
		<appender-ref ref="WARN_FILE"/>
		<appender-ref ref="ERROR_FILE"/>
	</root>

	<springProfile name="dev">
		<root level="INFO">
			<appender-ref ref="CONSOLE_APPENDER"/>
			<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
			<appender-ref ref="INFO_FILE"/>
			<appender-ref ref="DEBUG_FILE"/>
			<appender-ref ref="WARN_FILE"/>
			<appender-ref ref="ERROR_FILE"/>
		</root>
	</springProfile>

	<springProfile name="test">
		<root level="INFO">
			<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
			<appender-ref ref="INFO_FILE"/>
			<appender-ref ref="DEBUG_FILE"/>
			<appender-ref ref="WARN_FILE"/>
			<appender-ref ref="ERROR_FILE"/>
		</root>
	</springProfile>

	<springProfile name="pre">
		<root level="INFO">
			<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
			<appender-ref ref="INFO_FILE"/>
			<appender-ref ref="DEBUG_FILE"/>
			<appender-ref ref="WARN_FILE"/>
			<appender-ref ref="ERROR_FILE"/>
		</root>
	</springProfile>

	<springProfile name="pro">
		<root level="INFO">
			<appender-ref ref="KAFKA_ASYNC_APPENDER"/>
			<appender-ref ref="INFO_FILE"/>
			<appender-ref ref="DEBUG_FILE"/>
			<appender-ref ref="WARN_FILE"/>
			<appender-ref ref="ERROR_FILE"/>
		</root>
	</springProfile>
</configuration>
