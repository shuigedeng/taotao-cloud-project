server:
  port: 33413
  http2:
    enabled: true
  undertow:
    buffer-size: 2048
    direct-buffers: true
    threads:
      io: 16
      worker: 256
    accesslog:
      dir: ${user.home}/logs/undertow/${spring.application.name}
      enabled: true
  servlet:
    application-display-name: ${spring.application.name}

jasypt:
  encryptor:
    password: ${TAOTAO_CLOUD_ENCRYPTOR_PASSWORD:taotao-cloud}
    algorithm: PBEWITHHMACSHA512ANDAES_256
    property:
      prefix: "ENC@["
      suffix: "]"

redisson:
  password: ${TAOTAO_CLOUD_REDIS_PASSWORD:taotao-cloud}
  single-server-config:
    address: ${TAOTAO_CLOUD_REDIS_HOST:127.0.0.1}:${TAOTAO_CLOUD_REDIS_PORT:6379}

dubbo:
  application:
    id: ${spring.application.name}
    name: ${spring.application.name}
    qos-enable: false
    qos-accept-foreign-ip: false
  registry:
    address: nacos://${TAOTAO_CLOUD_NACOS_DISCOVERY_HOST:127.0.0.1}:${TAOTAO_CLOUD_NACOS_DISCOVERY_PORT:8848}
    timeout: 15000
  protocol:
    name: dubbo
    port: -1
    #serialization: kryo
  cloud:
    subscribed-services: 'taotao-cloud-sys'
  scan:
    base-packages: com.taotao.cloud.order.biz.service.impl
  provider:
    loadbalance: roundrobin
  consumer:
    check: false
    loadbalance: roundrobin
  config-center:
    check: false

seata:
  enabled: true
  application-id: ${spring.application.name}
  tx-service-group: taotao_cloud_tx_group
  enable-auto-data-source-proxy: true
  service:
    grouplist:
      default: ${TAOTAO_CLOUD_SEATA_HOST:127.0.0.1}:${TAOTAO_CLOUD_SEATA_PORT:8091}
    vgroup-mapping:
      taotao_cloud_tx_group: default
  config:
    type: nacos
    nacos:
      namespace: 6f9ac92d-8a72-4581-92b0-af71dbd67e2e
      server-addr: ${TAOTAO_CLOUD_SEATA_CONFIG_NACOS_HOST:127.0.0.1}:${TAOTAO_CLOUD_SEATA_CONFIG_NACOS_PORT:8848}
      group: SEATA_GROUP
      username: ${TAOTAO_CLOUD_SEATA_CONFIG_NACOS_USERNAME:nacos}
      password: ${TAOTAO_CLOUD_SEATA_CONFIG_NACOS_PASSWORD:nacos}
  registry:
    type: nacos
    nacos:
      application: taotao-cloud-seata
      server-addr: ${TAOTAO_CLOUD_SEATA_REGISTRY_NACOS_HOST:127.0.0.1}:${TAOTAO_CLOUD_SEATA_REGISTRY_NACOS_PORT:8848}
      group: SEATA_GROUP
      namespace: 6f9ac92d-8a72-4581-92b0-af71dbd67e2e
      username: ${TAOTAO_CLOUD_SEATA_REGISTRY_NACOS_USERNAME:nacos}
      password: ${TAOTAO_CLOUD_SEATA_REGISTRY_NACOS_PASSWORD:nacos}
      cluster: default

arthas:
  # telnetPort、httpPort为 -1 ，则不listen telnet端口，为 0 ，则随机telnet端口
  # 如果是防止一个机器上启动多个 arthas端口冲突。可以配置为随机端口，或者配置为 -1，并且通过tunnel server来使用arthas。
  # ~/logs/arthas/arthas.log (用户目录下面)里可以找到具体端口日志
  telnetPort: -1
  httpPort: -1
  # 127.0.0.1只能本地访问，0.0.0.0则可网络访问，但是存在安全问题
  ip: 0.0.0.0
  agent-id: ${spring.application.name}
  app-name: ${spring.application.name}
  tunnel-server: ws://127.0.0.1:7777/ws

spring:
  application:
    name: taotao-cloud-order
  main:
    allow-circular-references: false
    allow-bean-definition-overriding: false
    banner-mode: off
  web:
    resources:
      # pro环境关闭
      add-mappings: true
  mvc:
    servlet:
      load-on-startup: 1
  servlet:
    multipart:
      enabled: true
      file-size-threshold: 2KB
      max-file-size: 200MB
      max-request-size: 215MB
  opentelemetry:
    logging:
      export:
        otlp:
          compression: none
          endpoint: http://192.168.218.2:4318/v1/logs
          timeout: 10s
          headers:
            version: 2026.02
    tracing:
      export:
        otlp:
          compression: none
          endpoint: http://192.168.218.2:4318/v1/traces
          timeout: 10s
          headers:
            version: 2026.02
  otlp:
    metrics:
      export:
        url: http://192.168.218.2:4318/v1/metrics
        enabled: true
        batch-size: 10000
        connect-timeout: 10s
        headers:
          version: 2026.02
  observations:
    annotations:
      enabled: true
    http:
      client:
        requests:
          name: "ttc-request-name"
      server:
        requests:
          name: "ttc.server.name"
    key-values:
      application: ${spring.application.name}
  datasource:
    type: com.zaxxer.hikari.HikariDataSource
    url: jdbc:p6spy:mysql://${TAOTAO_CLOUD_MYSQL_HOST:127.0.0.1}:${TAOTAO_CLOUD_MYSQL_PORT:3306}/${spring.application.name}?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
    username: ${TAOTAO_CLOUD_MYSQL_USERNAME:root}
    password: ${TAOTAO_CLOUD_MYSQL_PASSWORD:123456}
    driver-class-name: com.p6spy.engine.spy.P6SpyDriver
    hikari:
      auto-commit: true
      connection-timeout: 30000
      idle-timeout: 25000
      login-timeout: 5
      validation-timeout: 3000
      max-lifetime: 50000
      read-only: false
      connection-test-query: SELECT 1
      maximum-pool-size: 15
      minimum-idle: 10
      pool-name: DatebookHikariCP
      register-mbeans: true
      data-source-properties:
        cachePrepStmts: true
        prepStmtCacheSize: 250
    dynamic:
      enabled: false
      datasource:
        master:
          type: com.zaxxer.hikari.HikariDataSource
          url: jdbc:p6spy:mysql://${TAOTAO_CLOUD_MYSQL_HOST:127.0.0.1}:${TAOTAO_CLOUD_MYSQL_PORT:3306}/${spring.application.name}?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
          username: ${TAOTAO_CLOUD_MYSQL_USERNAME:root}
          password: ${TAOTAO_CLOUD_MYSQL_PASSWORD:123456}
          driver-class-name: com.p6spy.engine.spy.P6SpyDriver
          hikari:
            auto-commit: true
            connection-timeout: 30000
            idle-timeout: 25000
            login-timeout: 5
            validation-timeout: 3000
            max-lifetime: 50000
            read-only: false
            connection-test-query: SELECT 1
            maximum-pool-size: 15
            minimum-idle: 10
            pool-name: DatebookHikariCP
            register-mbeans: true
            data-source-properties:
              cachePrepStmts: true
              prepStmtCacheSize: 250
  jpa:
    database: mysql
    #hibernate.show_sql 配置属性，因为它基本上等同于使用 System.out.println 打印 SQL 查询
    #如果要记录SQL，请不要使用show_sql方式，它是不会记录到日志文件中的，只会输出到控制台中
    show-sql: true
    open-in-view: false
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: true
        dialect: org.hibernate.dialect.MySQL8Dialect
  data:
    redis:
      host: ${TAOTAO_CLOUD_REDIS_HOST:127.0.0.1}
      port: ${TAOTAO_CLOUD_REDIS_PORT:6379}
      database: 1
      password: ${TAOTAO_CLOUD_REDIS_PASSWORD:taotao-cloud}
      lettuce:
        pool:
          max-active: 1500
          max-wait: 5000
          max-idle: 500
          min-idle: 100
      connect-timeout: 60s
    elasticsearch:
      rest:
        uris:
          - ${TAOTAO_CLOUD_ELASTICSEARCH_HOST:127.0.0.1}:${TAOTAO_CLOUD_ELASTICSEARCH_PORT:9200}
        username:
        password:
    elasticsearch:
      repositories:
        enabled: true
      client:
        reactive:
          endpoints:
            - ${TAOTAO_CLOUD_ELASTICSEARCH_HOST:127.0.0.1}:${TAOTAO_CLOUD_ELASTICSEARCH_PORT:9200}
          connection-timeout: 5
          username:
          password:
    mongodb:
      database: yapi
      host: 127.0.0.1
      port: 27017
      #username:
      #password:
  kafka:
    bootstrap-servers: ${TAOTAO_CLOUD_KAFKA_HOST:127.0.0.1}:${TAOTAO_CLOUD_KAFKA_PORT:9092}
    producer:
      retries: 1
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: 0
      properties:
        linger.ms: 100
    consumer:
      auto-commit-interval: 1S
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      concurrency: 5
      ack-mode: manual_immediate
      missing-topics-fatal: false
  security:
    oauth2:
      resourceserver:
        jwt:
          jwk-set-uri: http://127.0.0.1:9998/oauth2/jwks
  mail:
    host: smtp.qq.com
    password: ${TAOTAO_CLOUD_MAIL_PASSWORD:taotao-cloud}
    username: 981376577@qq.com
    port: 465
    protocol: smtps
    properties:
      smtp:
        auth: true
        timeout: 2500
      mail:
        smtp:
          ssl:
            enable: true
  shardingsphere:
    enabled: false
    # 分库分表 + 读写分离
    datasource:
      names: mysql-master-1,mysql-slave-1,mysql-master-2,mysql-slave-2
      mysql-master-1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://${TAOTAO-CLOUD-MYSQL-HOST:127.0.0.1}:${TAOTAO-CLOUD-NACOS-PORT:3306}/m1?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false
        username: ${TAOTAO-CLOUD-MYSQL-USERNAME:root}
        password: ${TAOTAO-CLOUD-MYSQL-PASSWORD:123456}
        driver-class-name: com.p6spy.engine.spy.P6SpyDriver
        hikari:
          auto-commit: true
          connection-timeout: 30000
          idle-timeout: 25000
          login-timeout: 5
          validation-timeout: 3000
          max-lifetime: 50000
          read-only: false
          connection-test-query: SELECT 1
          maximum-pool-size: 15
          minimum-idle: 10
          pool-name: DatebookHikariCP
          register-mbeans: true
          data-source-properties:
            cachePrepStmts: true
            prepStmtCacheSize: 250
      mysql-slave-1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://${TAOTAO-CLOUD-MYSQL-HOST:127.0.0.1}:${TAOTAO-CLOUD-NACOS-PORT:3307}/s1?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false
        username: ${TAOTAO-CLOUD-MYSQL-USERNAME:root}
        password: ${TAOTAO-CLOUD-MYSQL-PASSWORD:123456}
        driver-class-name: com.p6spy.engine.spy.P6SpyDriver
        hikari:
          auto-commit: true
          connection-timeout: 30000
          idle-timeout: 25000
          login-timeout: 5
          validation-timeout: 3000
          max-lifetime: 50000
          read-only: false
          connection-test-query: SELECT 1
          maximum-pool-size: 15
          minimum-idle: 10
          pool-name: DatebookHikariCP
          register-mbeans: true
          data-source-properties:
            cachePrepStmts: true
            prepStmtCacheSize: 250
      mysql-master-2:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://${TAOTAO-CLOUD-MYSQL-HOST:127.0.0.1}:${TAOTAO-CLOUD-NACOS-PORT:3308}/m2?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false
        username: ${TAOTAO-CLOUD-MYSQL-USERNAME:root}
        password: ${TAOTAO-CLOUD-MYSQL-PASSWORD:123456}
        driver-class-name: com.p6spy.engine.spy.P6SpyDriver
        hikari:
          auto-commit: true
          connection-timeout: 30000
          idle-timeout: 25000
          login-timeout: 5
          validation-timeout: 3000
          max-lifetime: 50000
          read-only: false
          connection-test-query: SELECT 1
          maximum-pool-size: 15
          minimum-idle: 10
          pool-name: DatebookHikariCP
          register-mbeans: true
          data-source-properties:
            cachePrepStmts: true
            prepStmtCacheSize: 250
      mysql-slave-2:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://${TAOTAO-CLOUD-MYSQL-HOST:127.0.0.1}:${TAOTAO-CLOUD-NACOS-PORT:3309}/s2?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false
        username: ${TAOTAO-CLOUD-MYSQL-USERNAME:root}
        password: ${TAOTAO-CLOUD-MYSQL-PASSWORD:123456}
        driver-class-name: com.p6spy.engine.spy.P6SpyDriver
        hikari:
          auto-commit: true
          connection-timeout: 30000
          idle-timeout: 25000
          login-timeout: 5
          validation-timeout: 3000
          max-lifetime: 50000
          read-only: false
          connection-test-query: SELECT 1
          maximum-pool-size: 15
          minimum-idle: 10
          pool-name: DatebookHikariCP
          register-mbeans: true
          data-source-properties:
            cachePrepStmts: true
            prepStmtCacheSize: 250
    sharding:
      default-database-strategy:
        ##根据用户ID分库
        inline:
          sharding-column: user_id
          algorithm-expression: mysql-master-$->{user_id % 2}
      tables:
        sys_user:
          #自增列名称，缺省表示不使用自增主键生成器
          #key-generator-column-name: order_id
          key-generator:
            #自增列名称，缺省表示不使用自增主键生成器
            column: order_id
            #雪花算法，如果系统并发比较低，数据将分布不是很均匀
            type: SNOWFLAKE
            #工作机器唯一id，默认为0，最大1024
            props:
              worker:
                id: 2
          #根据订单ID分表
          actual-data-nodes: mysql-master-$->{0..1}.t_order_$->{0..1}
          table-strategy:
            inline:
              sharding-column: order_id
              algorithm-expression: t_order_$->{order_id % 2}
      master-slave-rules:
        #指定master0为主库，slave0为它的从库
        mysql-master-1:
          load-balance-algorithm-type: round_robin
          master-data-source-name: mysql-master-1
          slave-data-source-names: mysql-slave-1
        #指定master1为主库，slave1为它的从库
        mysql-master-2:
          load-balance-algorithm-type: round_robin
          master-data-source-name: mysql-master-2
          slave-data-source-names: mysql-slave-2
    props:
      #是否开启SQL显示，默认值: false
      sql:
        show: true
      #工作线程数量，默认值: CPU核数
      executor:
        size: 4
      #是否在启动时检查分表元数据一致性，默认值: false
      check:
        table:
          metadata:
            enabled: false
  rabbitmq:
    host: 127.0.0.1
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    #消费端配置
    listener:
      simple:
        #自动签收auto  手动 manual
        acknowledge-mode: manual
  cloud:
    compatibility-verifier:
      enabled: false
    loadbalancer:
      enabled: true
    function:
      # functionName对应服务中的Bean
      definition: inputKafka1;inputKafka2;inputRabbit1;inputRabbit2
    stream:
      bindings:
        sms-output:
          destination: sms-topic
          binder: rabbit
        sms-input:
          destination: sms-topic
          group: sms-group
          binder: rabbit
        email-output:
          destination: email-topic
          #content-type: application/json
          binder: rocketmq
        email-input:
          destination: email-topic
          group: email-group
          binder: rocketmq
          consumer:
            #并发消费线程数
            concurrency: 20
        order-output:
          destination: order-topic
          #content-type: application/json
          binder: kafka
        order-input:
          destination: order-topic
          group: order-group
          binder: kafka
        # function kafka binding
        outputKafka-out-0:
          binder: kafka
          destination: destination-test-kafka-topic
        inputKafka1-in-0:
          binder: kafka
          destination: destination-test-kafka-topic
          group: group1
        inputKafka2-in-0:
          binder: kafka
          destination: destination-test-kafka-topic
          group: group2
        # function rabbit binding
        outputRabbit-out-0:
          binder: rabbit
          destination: destination-test-rabbit
          producer:
            partitioned: true
            partition-key-expression: headers['partitionKey']
            partition-count: 2
            required-groups:
              - myGroup
        inputRabbit1-in-0:
          binder: rabbit
          destination: destination-test-rabbit
          group: group1
        inputRabbit2-in-0:
          binder: rabbit
          destination: destination-test-rabbit
          group: group2
      rocketmq:
        binder:
          name-server: 127.0.0.1:9876;127.0.0.1:9876;
      rabbit:
        binder:
          admin-addresses: 127.0.0.1:5672,127.0.0.1:5672,
        bindings:
          sms-output:
            producer:
              #routing-key-expression: headers.routingKey   # 发送端路由key
              delayed-exchange: false    # 开启延时队列
          sms-input:
            consumer:
              #binding-routing-key: login.user.succeed   # 生产监听路由表达式
              delayed-exchange: false    # 开启延时队列
              #auto-bind-dlq: true   # 绑定死信队列
              #republish-to-dlq: true  # 重投到死信队列并带有报错信息
      kafka:
        binder:
          brokers: 127.0.0.1:9092
          auto-create-topics: true
          autoAddPartitions: true
        bindings:
          order-output:
            producer:
              sync: true
              bufferSize: 16384
          order-input:
            consumer:
              txCommitRecovered: true

taotao:
  boot:
    elasticsearch:
      enabled: true
    mongodb:
      enabled: true
    disruptor:
      enabled: true
      multi-producer: false
      ring-buffer-size: 1024
      ring-thread-numbers: 4
      #handler-definitions:
      # - /Event-DC-Output/TagA-Output/** = emailHandler
      # - /Event-DC-Output/TagB-Output/** = smsHandler
    health:
      enabled: true
      dump: true
      export: true
      warn: true
      check: true
    hibernate:
      enabled: true
      packages: com.taotao.cloud.order.biz.entity
    canal:
      enabled: false
      instances:
        example:
          clusterEnabled: false
          zookeeperAddress: 127.0.0.1:2181
          host: 127.0.0.1
          port: 11111
          userName: canal
          password: 123456
          batchSize: 1000
          filter:
          retryCount: 3
          acquireInterval: 3000
    core:
      env: dev
      enabled: true
    captcha:
      enabled: true
    zookeeper:
      enabled: true
      connectString: 127.0.0.1:2181
      lock:
        enabled: false
    web:
      dozer:
        enabled: true
      encrypt:
        enabled: true
      interceptor:
        doubt-api: true
        header: true
        prometheus: true
      filter:
        version: true
        tenant: true
        trace: true
        web-context: true
        report: true
        ping: true
        dump: true
      limit:
        enabled: true
      idempotent:
        enabled: true
      xss:
        enabled: true
    sms:
      enabled: false
    shardingsphere:
      enabled: false
    sentinel:
      enabled: true
    seata:
      enabled: true
    log:
      request-log:
        enabled: true
        types:
          - kafka
          - logger
    p6spy:
      enabled: true
      dateformat: yyyy-MM-dd HH:mm:ss
      driverlist: com.mysql.cj.jdbc.Driver
      database-dialect-date-format: yyyy-MM-dd HH:mm:ss
      appender: com.taotao.cloud.p6spy.logger.P6spyLogger
    redis:
      lock:
        enabled: true


    cache:
      enabled: true
      type: redis
    rabbitmq:
      enabled: false
    springdoc:
      enabled: true

mybatis-plus:
  mapper-locations: classpath:/mapper/*Mapper.xml
  typeAliasesPackage: com.taotao.cloud.*.biz.entity
  global-config:
    db-config:
      id-type: auto
      table-underline: true
      logic-delete-value: 1
      logic-not-delete-value: 0
      insert-strategy: ignored
      update-strategy: ignored
      where-strategy: ignored
  configuration:
    map-underscore-to-camel-case: true
    cache-enabled: false
    log-impl: com.taotao.boot.data.mybatis.log.StandardStdOutImpl


  okhttp:
    enabled: true
  httpclient:
    enabled: false
    max-connections: 1000
    max-connections-per-route: 100

  compression:
    request:
      enabled: true
      mime-types: text/xml,application/xml,application/json
      min-request-size: 2048
    response:
      enabled: true

management:
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    metrics:
      enabled: true
    prometheus:
      enabled: true
    health:
      show-details: ALWAYS
    shutdown:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
  health:
    elasticsearch:
      enabled: false

logging:
  level:
    root: INFO
    org.springframework.web: off
    org.springframework.security: off
    org.springframework.security.oauth2: off
    org.springframework.boot.autoconfigure: off
    org.springframework.cloud.openfeign: off
    org:
      springframework:
        cloud:
          stream:
            binder:
              rocketmq: DEBUG

springdoc:
  packages-to-exclude:
    - cn.afterturn.easypoi.wps.controller
    - com.taotao.boot.captcha.controller

pulsar:
  service-url: pulsar://127.0.0.1:6650
  io-threads: 10
  listener-threads: 10
  enable-tcp-no-delay: false
  keep-alive-interval-sec: 20
  connection-timeout-sec: 10
  operation-timeout-sec: 15
  starting-backoff-interval-ms: 100
  max-backoff-interval-sec: 10
  consumer-name-delimiter:
  namespace: default
  tenant: public
  consumer.default.dead-letter-policy-max-redeliver-count: -1
  consumer.default.ack-timeout-ms: 3000

liteflow:
  #规则文件路径
  rule-source: config/flow.el.xml
  rule-source-ext-data-map:
    serverAddr: 127.0.0.1:8848
    dataId: demo_rule
    group: DEFAULT_GROUP
    namespace: your namespace id
    username: nacos
    password: nacos
  #-----------------以下非必须-----------------
  #liteflow是否开启，默认为true
  enable: true
  #liteflow的banner打印是否开启，默认为true
  print-banner: true
  #zkNode的节点，只有使用zk作为配置源的时候才起作用，默认为/lite-flow/flow
  zk-node: /lite-flow/flow
  #上下文的最大数量槽，默认值为1024
  slot-size: 1024
  #FlowExecutor的execute2Future的线程数，默认为64
  main-executor-works: 64
  #FlowExecutor的execute2Future的自定义线程池Builder，LiteFlow提供了默认的Builder
  main-executor-class: com.yomahub.liteflow.thread.LiteFlowDefaultMainExecutorBuilder
  #自定义请求ID的生成类，LiteFlow提供了默认的生成类
  request-id-generator-class: com.yomahub.liteflow.flow.id.DefaultRequestIdGenerator
  #并行节点的线程池Builder，LiteFlow提供了默认的Builder
  thread-executor-class: com.yomahub.liteflow.thread.LiteFlowDefaultWhenExecutorBuilder
  #异步线程最长的等待时间(只用于when)，默认值为15000
  when-max-wait-time: 15000
  #异步线程最长的等待时间(只用于when)，默认值为MILLISECONDS，毫秒
  when-max-wait-time-unit: MILLISECONDS
  #when节点全局异步线程池最大线程数，默认为16
  when-max-workers: 16
  #并行循环子项线程池最大线程数，默认为16
  parallelLoop-max-workers: 16
  #并行循环子项线程池等待队列数，默认为512
  parallelLoop-queue-limit: 512
  #并行循环子项的线程池Builder，LiteFlow提供了默认的Builder
  parallelLoop-executor-class: com.yomahub.liteflow.thread.LiteFlowDefaultParallelLoopExecutorBuilder
  #when节点全局异步线程池等待队列数，默认为512
  when-queue-limit: 512
  #是否在启动的时候就解析规则，默认为true
  parse-on-start: true
  #全局重试次数，默认为0
  retry-count: 0
  #是否支持不同类型的加载方式混用，默认为false
  support-multiple-type: false
  #全局默认节点执行器
  node-executor-class: com.yomahub.liteflow.flow.executor.DefaultNodeExecutor
  #是否打印执行中过程中的日志，默认为true
  print-execution-log: true
  #是否开启本地文件监听，默认为false
  enable-monitor-file: false
  #简易监控配置选项
  monitor:
    #监控是否开启，默认不开启
    enable-log: false
    #监控队列存储大小，默认值为200
    queue-limit: 200
    #监控一开始延迟多少执行，默认值为300000毫秒，也就是5分钟
    delay: 300000
    #监控日志打印每过多少时间执行一次，默认值为300000毫秒，也就是5分钟
    period: 300000
